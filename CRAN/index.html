

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-146100304-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-146100304-1');
  </script>
  
  
  <script src="http://www.google.com/jsapi" type="text/javascript"></script>
  <script type="text/javascript">google.load("jquery", "1.3.2");</script>
  </head>
  
  
  <!-- Global site tag (gtag.js)
  <style>
  table, th, td {
    border: 1px solid black;
  }
  </style>
   - Google Analytics -->
   
  <style type="text/css">
      body {
          font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
          font-weight:300;
          font-size:18px;
          margin-left: auto;
          margin-right: auto;
          width: 1100px;
      }
  
      h1 {
          font-weight:300;
          margin: 0.4em;
      }
  
      p {
          margin: 0.2em;
      }
  
      .disclaimerbox {
          background-color: #eee;
          border: 1px solid #eeeeee;
          border-radius: 10px ;
          -moz-border-radius: 10px ;
          -webkit-border-radius: 10px ;
          padding: 20px;
      }
  
      video.header-vid {
          height: 140px;
          border: 1px solid black;
          border-radius: 10px ;
          -moz-border-radius: 10px ;
          -webkit-border-radius: 10px ;
      }
  
      img.header-img {
          height: 140px;
          border: 1px solid black;
          border-radius: 10px ;
          -moz-border-radius: 10px ;
          -webkit-border-radius: 10px ;
      }
  
      img.rounded {
          border: 1px solid #eeeeee;
          border-radius: 10px ;
          -moz-border-radius: 10px ;
          -webkit-border-radius: 10px ;
      }
  
      a:link,a:visited
      {
          color: #1367a7;
          text-decoration: none;
      }
      a:hover {
          color: #208799;
      }
  
      td.dl-link {
          height: 160px;
          text-align: center;
          font-size: 22px;
      }
  
      .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
          box-shadow:
                  0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                  5px 5px 0 0px #fff, /* The second layer */
                  5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                  10px 10px 0 0px #fff, /* The third layer */
                  10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                  15px 15px 0 0px #fff, /* The fourth layer */
                  15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                  20px 20px 0 0px #fff, /* The fifth layer */
                  20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                  25px 25px 0 0px #fff, /* The fifth layer */
                  25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
          margin-left: 10px;
          margin-right: 45px;
      }
  
  
      .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
          box-shadow:
                  0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                  5px 5px 0 0px #fff, /* The second layer */
                  5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                  10px 10px 0 0px #fff, /* The third layer */
                  10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
          margin-top: 5px;
          margin-left: 10px;
          margin-right: 30px;
          margin-bottom: 5px;
      }
  
      .vert-cent {
          position: relative;
          top: 50%;
          transform: translateY(-50%);
      }
  
      hr
      {
          margin: 0;
          border: 0;
          height: 1.5px;
          background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
      }
      
      .rotate {
          /* FF3.5+ */
          -moz-transform: rotate(-90.0deg);
          /* Opera 10.5 */
          -o-transform: rotate(-90.0deg);
          /* Saf3.1+, Chrome */
          -webkit-transform: rotate(-90.0deg);
          /* IE6,IE7 */
          filter: progid: DXImageTransform.Microsoft.BasicImage(rotation=0.083);
          /* IE8 */
          -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0.083)";
          /* Standard */
          transform: rotate(-90.0deg);
      }
      
      c {
         white-space: nowrap;
         writing-mode: tb-rl;
         transform: rotate(-180.0deg);
      }
  
  </style>
  
  <html>
    <head>
          <title>CRAN</title>
          <meta property="og:title" content="nlos" />
    </head>
  
    <body>
        <br>
        <center>
        <span style="font-size:42px">Reciprocal Translation between SAR and Optical <br>  Remote Sensing Images with Cascaded-residual <br> adversarial Networks</span>
        </center>

        <br>
        <table align=center width=700px>
            <tr>
                <td align=center width=120px>
                    <center>
                    <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=DhRWSrgAAAAJ&hl=en&oi=ao">Shilei Fu</a></span>
                    </center>
                </td>

                <td align=center width=120px>
                    <center>
                    <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=i-N1K9oAAAAJ&hl=en&oi=ao">Feng Xu</a></span>
                    </center>
                </td>

                <td align=center width=120px>
                    <center>
                    <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=sjiN70AAAAAJ&hl=en&oi=ao">Ya-Qiu Jin</a></span>
                    </center>
                </td>
            </tr>
        </table>
        <br>
      
        <table align=center width=700px>
            <tr>
                <td align=center width=100px>
                    <center>
                    <span style="font-size:20px;color:red">Science China, 2021</span>
                    </center>
                </td>
            </tr>
        </table>

        <br>
        <br>
        <table align=center width=900px>
            <tr>
                <td width=900px>
                    <center>
                    <a href="./figures/1_Flow_chart.png"><img src = "./figures/1_Flow_chart.png" width="900px"></img></href></a><br>
                    </center>
                </td>
            </tr>
        </table>

        <table align=center width=900px></table>
            <tr>
                <td width=600px>
                    <br>  
                    <center>
                    <span style="font-size:14px"><i>We propose an adversarial Networks scheme where cascaded residual connections and hybrid L1-GAN loss are employed to tackles the problem of SAR-optical reciprocal translation.</i>
                    </center>
                </td>
            </tr>
        </table>

        <table align=center width=900px></table>
            <tr>
                <td colspan='2'>
                    <center>
                    <a href="figures/2_translator.png"><img src = "figures/2_translator.png" width="400px"></img></a><br>
                    </center>
                </td>

                <td colspan='2'>
                    <center>
                    <a href="figures/3_discriminator.png"><img src = "figures/3_discriminator.png" width="200px"></img></a><br>
                    </center>
                </td>
                
            </tr>
        </table>

        <table align=center width=900px></table>
                <tr>
                    <td width=600px>
                    <br>  
                    <center>
                        <span style="font-size:14px"><i>We propose an adversarial Networks scheme where cascaded residual connections and hybrid L1-GAN loss are employed to tackles the problem of SAR-optical reciprocal translation.</i>
                    </center>
                    </td>
                </tr>
                <tr>
                    <td width=600px>
                        <br>
                        <p align="justify" style="font-size: 18px">
                        Despite the advantages of all-weather and all-day high-resolution imaging, synthetic aperture radar (SAR) images are much less viewed and used by general people because human vision is not adapted to microwave scattering phenomenon. However, expert interpreters can be trained by comparing side-byside SAR and optical images to learn the mapping rules from SAR to optical. This paper attempts to develop machine intelligence that is trainable with large-volume co-registered SAR and optical images to translate SAR images to optical version for assisted SAR image interpretation. Reciprocal SAR-optical image translation is a challenging task because it is a raw data translation between two physically very different sensing modalities. Inspired by recent progresses in image translation studies in computer vision, this paper tackles the problem of SAR-optical reciprocal translation with an adversarial network scheme where cascaded residual connections and hybrid L1-GAN loss are employed. It is trained and tested on both spaceborne Gaofen-3 (GF-3) and airborne Uninhabited Airborne Vehicle Synthetic Aperture Radar (UAVSAR) images. Results are presented for datasets of different resolutions and polarizations and compared with other state-of-the-art methods. The Frechet inception distance (FID) is used to quantitatively evaluate the translation performance. The possibility of unsupervised learning with unpaired/unregistered SAR and optical images is also explored. Results show that the proposed translation network works well under many scenarios and it could potentially be used for assisted SAR interpretation.
                        </p>
                    </td>
                </tr>
            </table>

        <br>
        <hr>
        <!-- <table align=center width=550px> -->
        <table align=center width=700>
            <center><h1>Paper</h1></center>
            <tr>
                <td><a href="./files/CRAN.pdf"><img style="height:180px; border: solid; border-radius:30px;" src="./files/paper.png"/></a></td>
                <td><span style="font-size:18px"> Shilei Fu, Feng Xu, Ya-Qiu Jin <br><br>
                Reciprocal Translation between SAR and Optical Remote Sensing Images with Cascaded-residual adversarial Networks<br>
                </td>
            </tr>
        </table>

        <br>

        <table align=center width=700px>
            <tr>
                <td><span style="font-size:18px">
                    <center>
                    <a href="./files/CRAN.pdf">[Paper]</a>
                    </center>
                </td>

                <td><span style="font-size:18px">
                    <center>
                    <a href="./files/supplement.pdf">[Supplement]</a>
                    </center>
                </td>
                
                <td><span style="font-size:18px">
                    <center>
                    <a href="./files/bib.txt">[Bibtex]</a>
                    </center>
                </td>

                <td><span style="font-size:18px">
                    <center>
                    <a href="https://github.com/Shilling818/CRAN">[Code]</a>
                    </center>
                </td>
            </tr>
        </table>
        
        <br>
        <table align=center width=700px>
            <tr>
                <td colspan="5" style="font-size: 14px">
                    <center>
                    <i> Please address correspondence regarding this paper to <a href="mailto:fengxu@fudan.edu.cn">Feng Xu</a>.</i>
                    </center>
                </td>
            </tr>
        </table>
        
        
        <br>
        <hr>

        <center><h1>Results</h1></center>
        
        <br>
        <table align=center width=900px>
            
            <tr>
            
                <td colspan='2'>
                    <center>
                        <a href="figures/4_resolution_1.png"><img src = "figures/4_resolution_2.png" width="900px"></img></a><br>
                    </center>
                </td>
            </tr>

            <tr>
            
                <td colspan='2'>
                    <center>
                        <a href="figures/4_resolution_2.png"><img src = "figures/4_resolution_1.png" width="900px"></img></a><br>
                    </center>
                </td>
            </tr>
            
        </table>
        
        <table align=center width=900px>
            <tr>
                <td>
                    <p  align="justify" >
                    <span style="font-size:18px">
                    <hr style="height:12pt; visibility:hidden;" /> <!–– Spacing -->
                    <b>Translating images with different resolutions.</b>
                    </span>	
                    <br>
                    </p>

                    <p  align="justify" >
                    <span style="font-size:15px">	
                    The first two rows are chosen from GF-3 dataset, the third row is 6m UAVSAR dataset, and the fourth is from 10m UAVSAR dataset. Images in each row from left to right are the real SAR image ((a1), (a2)) and its translated optical image ((b1), (b2)), the real optical image ((c1), (c2)) and its translated SAR image ((d1), (d2)).
                    </span>	
                    </p>					
                </td>
            
            </tr>
            
        </table>
        
        <br>
        <br>
        
        
        <table align=center width=900px>
            <tr>
                <td width=900px>
                    <center>
                        <a href="./figures/5_Polarization.png"><img src = "./figures/5_Polarization.png" width="900px"></img></href></a><br>
                </center>
                </td>
            </tr>
        </table>
        
        
        <table align=center width=900px>
            <tr>
                <td>  
                    <span style="font-size:18px">
                    <hr style="height:12pt; visibility:hidden;" /> <!–– Spacing -->
                    <b>Translaing images with different polarization modes.</b>
                    </span>	
                    <br>

                    <p  align="justify" >
                    <span style="font-size:15px">
                    Images listed above in each row are (a) the optical ground truth and (b) its translated single-pol SAR image and (c) translated full-pol SAR image, (d) the single-pol SAR ground truth and (e) the optical image translated by single-pol SAR image, (f) the full-pol SAR ground truth and (g) the optical image translated by full-pol SAR image in order. Each row lists a kind of earth surfaces: waters, vegetation, farmlands and buildings.
                    </span>	
                    </p>					
                </td>
            </tr> 
        </table>
        
        
        <br>
        <br>
        <table align=center width=900px>
            <tr>
                <td width=900px>
                    <center>
                        <a href="./figures/6_comparison.png"><img src = "./figures/6_comparison.png" width="900px"></img></href></a><br>
                </center>
                </td>
            </tr>
        </table>

        <table align=center width=900px>
            <tr>
                <td>  
                    <span style="font-size:18px">
                    <hr style="height:12pt; visibility:hidden;" /> <!–– Spacing -->
                    <b>Comparison of SAR-optical translation by different methods.</b>
                    </span>	
                    <br>

                    <p  align="justify" >
                    <span style="font-size:15px">
                    Images in each row from left to right are (a) the real optical image, (b) the input SAR image, (c) its translated optical image by CycleGAN, (d) the translated optical image by Pix2Pix and (e) the translated optical image by CRAN. Each row lists a kind of earth surfaces: buildings, buildings, farmlands and roads.
                    </span>	
                    </p>					
                </td>
            </tr> 
        </table>


        <br>
        <br>
        <table align=center width=900px>
            <tr>
                <td width=900px>
                    <center>
                        <a href="./figures/7_refinement.png"><img src = "./figures/7_refinement.png" width="900px"></img></href></a><br>
                </center>
                </td>
            </tr>
        </table>

        <table align=center width=900px>
            <tr>
                <td>  
                    <span style="font-size:18px">
                    <hr style="height:12pt; visibility:hidden;" /> <!–– Spacing -->
                    <b>Translated images further refined with unsupervised learning.</b>
                    </span>	
                    <br>

                    <p  align="justify" >
                    <span style="font-size:15px">
                    Images in each row from left to right are (a) the input SAR image, (b) the translated optical image and (c) the further refined optical image by unsupervised learning, (d) the input optical image and (e) its translated SAR image and (f) the further refined SAR image by unsupervised learning. Each row lists a kind of earth surfaces: waters, vegetation, farmlands and buildings.
                    </p>					
                </td>
            </tr> 
        </table>

        <br>
        <br>
        <table align=center width=900px>
            <tr>
                <td width=900px>
                    <center>
                        <a href="./figures/8_segmentation.png"><img src = "./figures/8_segmentation.png" width="900px"></img></href></a><br>
                </center>
                </td>
            </tr>
        </table>

        <table align=center width=900px>
            <tr>
                <td>  
                    <span style="font-size:18px">
                    <hr style="height:12pt; visibility:hidden;" /> <!–– Spacing -->
                    <b>Discussion: a contrastive experiment on SAR image segmentation.</b>
                    </span>	
                    <br>

                    <p  align="justify" >
                    <span style="font-size:15px">
                    Images in each row from left to right are (a) optical ground truth, (b) segmentation ground truth, (c) input SAR image, (d) map segmented from (c), (e) optical image generated from (c) by CRAN and (f) map segmented from (e). For segmentation maps, colors red, green, blue, yellow, and black represent buildings, vegetation, waters, roads, and others respectively.
                    </p>					
                </td>
            </tr> 
        </table>
        
    </body>
</html>
  
